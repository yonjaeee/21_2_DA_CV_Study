## Ch. 8 YOLO

### YOLO (You Only Look Once)

<img src="https://user-images.githubusercontent.com/77441568/137302737-3b347922-b33f-46e3-ac82-d56232cf58b6.png" alt="1" style="zoom: 80%;" />

- One Stage Detection의 지평을 열었음
- Real-Time Object Detection



#### YOLO Version

![2](https://user-images.githubusercontent.com/77441568/137302697-d2a920bf-1692-40ee-89c1-55a6f2eb4523.png)

- Yolo v1(2015.06) 
  - Detection 수행시간 단축, 성능은 많이 떨어짐
- Yolo v2(2016.12)
  -  SSD의 영향을 많이 받음
  -  SSD와 대등한 수행 성능
  -  수행 시간은 더 빠름
  - SSD에 비해 작은 Object 성능 저하
- Yolo v3(2018.04) 
  - v2 대비 수행시간 조금 느림
  - 성능은 대폭 개선됨
- Yolo v4(2020.04) 
  - v3 대비 수행 성능, 속도 매우 개선
- Retinanet: FPN을 적극적으로 활용, 작은 object에 대해 성능이 좋음
- EfficientDet: 속도는 떨어지지만 수행 성능은 높음

![3](https://user-images.githubusercontent.com/77441568/137302795-b4d3d1a7-eb81-4ba9-b6ad-b9239944f517.png)



### YOLO - V1

![4](https://user-images.githubusercontent.com/77441568/137302833-b47fd091-e3af-4fd8-bf7d-71cea32a780c.png)

- Input Image를 SxS Grid로 나누어 진행
- 각 Grid의 Cell이 하나의 Object에 대해 Detection 수행
- 작은 Object들에 대한 문제 존재
- 각 Grid Cell 별로 2개의 BBox를 만들고, 이를 기반으로 예측 수행



#### YOLO v1 Network

![5](https://user-images.githubusercontent.com/77441568/137302866-b3856b97-3774-47ca-8731-f85072f9541f.png)

- GoogLeNet 구조에 영감을 받아 Network 구성
- Inception module을 일자로 이어둔 모델 사용

![6](https://user-images.githubusercontent.com/77441568/137302892-5f1345bf-c949-4bcf-afd9-4df206c79540.png)

- Grid Cell (1x30 vector)
  - 2개의 BBox 후보의 좌표 / 해당 Box 별 Confidence Score 계산
    - x, y, w, h: 정규화된 BBox 중심 좌표와 너비/높이
    - Confidence Score = Object일 확률 * IOU 값
  - 각 클래스의 확률
    - 2개의 BBox 중 IOU가 가장 큰 Box 선택(책임 BBox)
    - 책임 BBox의 class 확률 계산 -> 20개
  - 위의 결과로 1x30 vector가 나오게 됨



#### YOLO v1 Loss

- BBox 중심 x, y 좌표

  ![7](https://user-images.githubusercontent.com/77441568/137302929-177a94a6-c36b-46ca-9694-fcc9cfb98166.png)

  - 책임 BBox만 Loss 계산
  - 책임 BBox:1 / 나머지:0

- BBox w, h

  ![8](https://user-images.githubusercontent.com/77441568/137302940-1617645e-8094-4ecd-8bb2-59de23a5e835.png)

  - 크기가 큰 Object는 상대적으로 오류가 커질 수 있음 --> 제곱근 사용

- Object Confidence Loss

  ![9](https://user-images.githubusercontent.com/77441568/137302955-3d0d7157-f745-4c22-8b08-5dbdb2a0df81.png)

  - C_i = P(Object) * IOU
  - 책임 BBox가 아닌 BBox도 값 계산
  - coord: 5 / noobj: 0.5

- Classification Loss

![10](https://user-images.githubusercontent.com/77441568/137302984-f8f58350-bd42-4cf9-9c28-b49b70f60fa7.png)



- 최종적으로, **NMS**로 BBox 예측



### YOLO - V2

#### YOLO Version 비교

![11](https://user-images.githubusercontent.com/77441568/137303022-d32d07b5-8d6c-4062-bc19-4075895afef3.png)



#### YOLO v2 성능

![12](https://user-images.githubusercontent.com/77441568/137303041-c02469aa-6cf3-43a0-b267-2a5c4a9d0901.png)



#### YOLO v2 특징

- **Batch Normalization**

  - 모든 Conv layer 뒤에 BN 추가
  - mAP 값이 2% 정도 향상
  - overfitting 없이 기타 Regularization 방법 / Dropout 제거

- **High Resolution Classifier**

  - Yolo v1은 darknet을 224x224 크기로 pre-train, detection 시에는 448x448 크기를 입력으로 사용
  - Yolo v2는 처음부터 darknet을 448x448 크기로 pre-train 시켜 높은 해상도의 이미지에 적응할 시간을 제공
  - mAP 값이 4% 정도 향상

- **Grid cell 별 5개의 Anchor box**

  - 네트워크를 줄여 416x416 크기의 입력 이미지 사용 (최종 output feature map의 크기가 홀수가 되도록 하여, feature map 내에 하나의 중심 cell이 존재할 수 있도록 만듦)
  - anchor box를 사용해 보다 많은 수의 Bbox 예측
  - anchor box의 크기, 좌표는 K-Means Clustering으로 설정

- **Direct Location Prediction**

  - Yolo와 Anchor box를 함께 사용했을 때, 초기 iter에서 모델이 불안정함

    ![13](https://user-images.githubusercontent.com/77441568/137303069-b1e898af-38cf-42b2-927a-8f057bd70605.png)

  - t_x, t_y와 같은 계수는 제한된 범위가 없기 때문에 최적값을 찾는 데 오랜 시간이 걸림

    <img src="https://user-images.githubusercontent.com/77441568/137303097-c24a569e-38c4-4c75-bc9f-f43083b33cc3.png" alt="14" style="zoom:80%;" />

  - sigmoid를 적용하여 0~1사이 값을 갖도록 조정 -> 안정적으로 학습할 수 있게됨

- **Darknet-19 Classification 모델 채택**
- **Multi-Scale Training**
  - FCL -> Fully Conv로 변경
  - 다양한 크기의 image로 학습



#### Anchor Box

![15](https://user-images.githubusercontent.com/77441568/137303134-087d0ef5-59e2-447c-a107-ed93c8e6f179.png)

- 여러 개의 Anchor box -> 여러 개 Object Detection 가능
- K-means Clustering을 통해 이미지 크기, shape ratio에 따른 5개의 군집화 분류



#### YOLO v2 Output Feature map

<img src="https://user-images.githubusercontent.com/77441568/137303152-1c1d8f4a-65b1-4213-b6a9-eb4ab7336318.png" alt="16" style="zoom:80%;" />

- YOLO v1과 달리 각 Anchor box 별로 Score 존재

#### YOLO v2 Loss

- v1와 유사한 Loss

  <img src="https://user-images.githubusercontent.com/77441568/137303215-9e7e1ae5-9c49-4ae6-af2a-c1e9141fd1dc.png" alt="17" style="zoom: 67%;" />

- 좌표값, 예측값만 변경



#### Passthrough module

![18](https://user-images.githubusercontent.com/77441568/137303283-fb157f13-09a7-40d6-87b5-56073c472136.png)

- feature map이 작아질 수록 작은 object 탐지 어려움

- reshape,  작은 image의 특징을 더해줌



#### Darknet 19 Backbone

<img src="https://user-images.githubusercontent.com/77441568/137303323-d04950e3-8bda-4374-bb30-b9d26c793498.png" alt="19" style="zoom:67%;" />



### YOLO V3

- Retinanet의 등장은 예측 성능을 매우 높임 -> FPN 사용

- YOLO v3 -> FPN 적용 -> 시간, 성능 모두 향상

- EfficientDet 등장 이전까지 Real-time detection의 주요 모델로 사용

- v2와 가장 큰 차이는 FPN, Darknet 53 사용

- 2015~2018 Resnet backbone 유행 but 속도 느림 -> Darknet 사용



#### FPN(Feature Pyramid Network)

![20](https://user-images.githubusercontent.com/77441568/137303354-81909699-3464-4234-9c0b-f5342765d2c5.png)

- 상위 feature map(upsample) + 하위 feature map -> 이전의 특징을 반영하여 예측



#### YOLO v3 특징

- 3개의 Feature map 생성(13x13, 26x26, 52x52)
- 3개의 Feature map은 각각 3개의 Anchor box를 가짐
- Darknet-53 사용(Backbone 성능 향상)
- Multi Labels 예측
  - Sigmoid 기반의 classifier로 개별 object의 multi labels 예측

![26](https://user-images.githubusercontent.com/77441568/137303390-301f6fb9-fc32-4cbb-ab28-641c7888e7c0.png)



#### YOLO v3 Model Architecture

![21](https://user-images.githubusercontent.com/77441568/137303415-c9b244e1-7633-4cf2-85e6-b2482e259d9e.png)



![22](https://user-images.githubusercontent.com/77441568/137303438-a86f5f7e-4243-4083-a500-4e1802f15292.png)

- 뽑아내는 output 정보가 매우 많음(FPN 적용)
- feature map 크기별 loss 계산 

![23](https://user-images.githubusercontent.com/77441568/137303467-28af41bd-3c14-4d3a-90bf-a31a2b1f5d4c.png)



#### Darknet-53

![24](https://user-images.githubusercontent.com/77441568/137303485-8801ff6f-d5b9-4003-a9a9-b45eb2e07e2c.png)

- ResNet과 비슷한 성능을 보여줌
- Shortcut connection 사용

![25](https://user-images.githubusercontent.com/77441568/137303520-78b04176-3e03-4dac-8166-d129d0b1a3bb.png)





#### YOLO v3 성능

![27](https://user-images.githubusercontent.com/77441568/137303552-8ef3f289-eed0-4632-bd9b-b2bbaaa2f282.png)


